"""
Text analyzer module for processing and analyzing text content.
"""

from typing import Dict, Optional, List, Tuple
import json
from pathlib import Path
from config.instances import openai_client
from config.settings import settings
from agent.memory_access.user_memory import user_memory
from agent.memory_access.name_memory import load_name_memory, add_name_to_memory
from utils.logger import logger
from rapidfuzz import fuzz, process
from skills.core.speech.speaker import say
from skills.core.listen.listener import record_and_transcribe

class TextAnalyzer:
    """Class for analyzing text content."""
    
    def __init__(self):
        """Initialize text analyzer."""
        pass
        
    async def analyze_conversation(
        self,
        user_message: str,
        assistant_message: str,
        user_id: str,
        target_user_id: Optional[str] = None
    ) -> None:
        """Analyze conversation and store extracted information.
        
        Args:
            user_message: Message from user
            assistant_message: Response from assistant
            user_id: ID of the user to store information for
            target_user_id: Optional ID of user being discussed
        """
        if user_id == "anonymous":
            return
            
        try:
            # Analyze conversation with GPT
            analysis_prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á:

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {user_message}
‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢: {assistant_message}

‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
{{
    "current_user": {{
        "basic_info": {{
            "name": "‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
            "nickname": "‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"
        }},
        "aliases": ["‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏û‡∏µ‡πà ‡∏ô‡πâ‡∏≠‡∏á ‡∏Ñ‡∏∏‡∏ì"],
        "name_preferences": {{
            "preferred_name": "‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
            "formality_level": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á (formal/informal/friendly)"
        }},
        "health_info": {{
            "last_meal": {{
                "time": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏∑‡πâ‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
                "food": ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏ô"],
                "is_healthy": true/false
            }},
            "symptoms": ["‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "sleep_quality": "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ô‡∏≠‡∏ô (good/fair/poor) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á",
            "stress_level": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î (low/medium/high) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á"
        }},
        "preferences": {{
            "likes": ["‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "dislikes": ["‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "favorite_foods": ["‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö"],
            "food_restrictions": ["‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£"]
        }},
        "relationships": {{
            "partner": "user_id ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡∏£‡∏±‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á)",
            "family": ["user_id ‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á)"]
        }}
    }},
    "mentioned_person": {{
        "basic_info": {{
            "name": "‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
            "nickname": "‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"
        }},
        "aliases": ["‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å babe ‡∏ô‡πâ‡∏≠‡∏á ‡∏û‡∏µ‡πà"],
        "name_preferences": {{
            "preferred_name": "‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
            "formality_level": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á (formal/informal/friendly)"
        }},
        "health_info": {{
            "last_meal": {{
                "time": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏°‡∏∑‡πâ‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
                "food": ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏ô"],
                "is_healthy": true/false
            }},
            "symptoms": ["‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "sleep_quality": "‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ô‡∏≠‡∏ô (good/fair/poor) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á",
            "stress_level": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î (low/medium/high) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á"
        }},
        "preferences": {{
            "likes": ["‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "dislikes": ["‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"],
            "favorite_foods": ["‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö"],
            "food_restrictions": ["‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£"]
        }},
        "relationships": {{
            "partner": "user_id ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡∏£‡∏±‡∏Å (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á)",
            "family": ["user_id ‡∏Ç‡∏≠‡∏á‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á)"]
        }}
    }}
}}"""

            response = await openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"},
                    {"role": "user", "content": analysis_prompt}
                ]
            )
            
            # Parse analysis results
            try:
                analysis = json.loads(response.choices[0].message.content)
            except json.JSONDecodeError:
                return
                
            # Update current user's information
            if current_user := analysis.get("current_user"):
                if basic_info := current_user.get("basic_info"):
                    if any(basic_info.values()):
                        user_memory.update_memory("basic_info", basic_info, user_id)
                        
                if aliases := current_user.get("aliases"):
                    if aliases:
                        user_memory.update_memory("aliases", aliases, user_id)
                        
                if name_prefs := current_user.get("name_preferences"):
                    if any(name_prefs.values()):
                        user_memory.update_memory("name_preferences", name_prefs, user_id)
                        
                if health_info := current_user.get("health_info"):
                    if any(health_info.values()):
                        user_memory.update_memory("health_info", health_info, user_id)
                        
                if preferences := current_user.get("preferences"):
                    if any(preferences.values()):
                        user_memory.update_memory("preferences", preferences, user_id)
                        
                if relationships := current_user.get("relationships"):
                    if any(relationships.values()):
                        user_memory.update_memory("relationships", relationships, user_id)
                        
            # Update mentioned person's information if target_user_id exists
            if target_user_id and (mentioned_person := analysis.get("mentioned_person")):
                if basic_info := mentioned_person.get("basic_info"):
                    if any(basic_info.values()):
                        user_memory.update_memory("basic_info", basic_info, target_user_id)
                        
                if aliases := mentioned_person.get("aliases"):
                    if aliases:
                        user_memory.update_memory("aliases", aliases, target_user_id)
                        
                if name_prefs := mentioned_person.get("name_preferences"):
                    if any(name_prefs.values()):
                        user_memory.update_memory("name_preferences", name_prefs, target_user_id)
                        
                if health_info := mentioned_person.get("health_info"):
                    if any(health_info.values()):
                        user_memory.update_memory("health_info", health_info, target_user_id)
                        
                if preferences := mentioned_person.get("preferences"):
                    if any(preferences.values()):
                        user_memory.update_memory("preferences", preferences, target_user_id)
                        
                if relationships := mentioned_person.get("relationships"):
                    if any(relationships.values()):
                        user_memory.update_memory("relationships", relationships, target_user_id)
                        
            # Store interaction
            user_memory.add_interaction("chat", {
                "user_message": user_message,
                "assistant_message": assistant_message,
                "target_user_id": target_user_id
            }, user_id)
            
        except Exception:
            # Silently fail if analysis fails
            pass
            
    async def analyze_references(self, user_message: str, current_user_id: str) -> Tuple[Optional[str], Dict]:
        """Analyze message to find references to other users.
        
        Args:
            user_message: Message from user
            current_user_id: Current user ID
            
        Returns:
            Tuple of (target_user_id, analysis_result)
        """
        if current_user_id == "anonymous":
            return None, {}
            
        try:
            # Use GPT to analyze references in the message
            analysis_prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏≠‡∏∑‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà:

"{user_message}"

‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
{{
    "references": [
        {{
            "text": "‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏•‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏Ç‡∏≤ ‡πÅ‡∏ü‡∏ô ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å)",
            "type": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (partner/family/friend)",
            "context": "‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"
        }}
    ],
    "is_same_person": true/false,
    "explanation": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏à‡∏∂‡∏á‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏•‡∏∞‡∏Ñ‡∏ô"
}}"""

            response = await openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏∂‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"},
                    {"role": "user", "content": analysis_prompt}
                ]
            )
            
            # Get content from the new response structure
            content = response.choices[0].message.content
            if not content:
                return None, {}
                
            analysis = json.loads(content)
            
            # If no references found
            if not analysis.get("references"):
                return None, analysis
                
            # Get current user's context
            user_context = user_memory.get_user_context(current_user_id)
            target_user_id = None
            
            # Check each reference
            for ref in analysis["references"]:
                if ref["type"] == "partner":
                    # Check existing partner
                    if partner_id := user_context.get("relationships", {}).get("partner"):
                        target_user_id = partner_id
                        break
                    # Create temporary user for new partner
                    else:
                        target_user_id = user_memory.create_temporary_user({
                            "relationships": {"partner": current_user_id}
                        })
                        user_memory.update_memory("relationships", {
                            "partner": target_user_id
                        }, current_user_id)
                        break
                        
                # Try to find by alias
                elif found_id := user_memory.find_user_by_alias(ref["text"], current_user_id):
                    target_user_id = found_id
                    break
                    
            return target_user_id, analysis
            
        except Exception as e:
            print(f"Error analyzing references: {str(e)}")
            return None, {}
            
    async def extract_name(self, text: str) -> Optional[str]:
        """Extract name from introduction text.
        
        Args:
            text: Text containing name introduction
            
        Returns:
            Extracted name if found, None otherwise
        """
        prompt = f"""
        ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏±‡∏ß: "{text}"
        
        ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢:
        1. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ä‡∏∑‡πà‡∏≠
        2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö null
        3. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        4. ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏∏‡∏ì, ‡∏ô‡∏≤‡∏¢, ‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß
        
        ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
        {{"name": "‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏ö ‡∏´‡∏£‡∏∑‡∏≠ null"}}
        """
        
        response = await openai_client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "You are a helpful assistant that extracts names from Thai text."
            }, {
                "role": "user",
                "content": prompt
            }]
        )
        
        try:
            result = response.choices[0].message.content
            name = json.loads(result)["name"]
            return name if name != "null" else None
        except:
            return None
            
    async def detect_wake_word(self, text: str, should_ask: bool = True) -> Tuple[bool, Optional[str]]:
        """Detect wake word in text and learn new variations.
        
        Args:
            text: Text to check for wake word
            should_ask: Whether to ask user about uncertain matches
            
        Returns:
            Tuple of (is_wake_word, matched_name)
        """
        name_memory = load_name_memory()
        
        # Convert to lowercase for case-insensitive matching
        text = text.lower()
        words = text.split()
        
        # Add main name from settings to name memory
        all_names = name_memory + [settings.ROBOT_NAME.lower()]
        
        # Check each word
        for word in words:
            # Find best match
            best_match = process.extractOne(
                word,
                all_names,
                scorer=fuzz.ratio,
                score_cutoff=80
            )
            
            if best_match:
                matched_name = best_match[0]
                score = best_match[1]
                logger.debug(f"[üîç] ‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á: '{word}' -> '{matched_name}' (score: {score})")
                return True, matched_name
                
            # Check uncertain matches
            uncertain_match = process.extractOne(
                word,
                all_names,
                scorer=fuzz.ratio,
                score_cutoff=60
            )
            
            if uncertain_match and should_ask:
                matched_name = uncertain_match[0]
                score = uncertain_match[1]
                logger.debug(f"[‚ùì] ‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠: '{word}' -> '{matched_name}' (score: {score})")
                say(f"‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '{word}' ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏°‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?")
                
                # Wait for response
                response = await record_and_transcribe()
                
                # Use GPT to analyze intent
                is_confirmed = await self.is_confirmation(response, f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '{word}' ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏∏‡πà‡∏ô‡∏¢‡∏ô‡∏ï‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
                if is_confirmed:
                    add_name_to_memory(word)
                    return True, word
        
        return False, None
        
    async def is_confirmation(self, text: str, context: str) -> bool:
        """Check if text is a confirmation.
        
        Args:
            text: Text to analyze
            context: Context of the question
            
        Returns:
            True if text is a confirmation, False otherwise
        """
        prompt = f"""
        ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó: {context}
        ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: "{text}"
        
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô (‡πÉ‡∏ä‡πà/‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á) ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò
        
        ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
        {{"is_confirmation": true/false}}
        """
        
        response = await openai_client.chat.completions.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "You are a helpful assistant that analyzes confirmation intent in Thai text. Always respond in JSON format."
            }, {
                "role": "user",
                "content": prompt
            }]
        )
        
        try:
            result = response.choices[0].message.content
            return json.loads(result)["is_confirmation"]
        except:
            return False

# Global instance
text_analyzer = TextAnalyzer() 